{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4a3f79f-410a-42d3-9629-6d9523c008ec",
   "metadata": {},
   "source": [
    "# Fine tune Vit built by Google Brain, which trained on ImageNet-21k, for Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd69063f-4aba-4633-8b72-1dfd298a02ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kang5647/.local/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "2024-04-12 15:58:36.975887: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-12 15:58:37.088967: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-04-12 15:58:37.088983: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-04-12 15:58:37.539274: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-04-12 15:58:37.539354: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-04-12 15:58:37.539359: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/kang5647/.local/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/kang5647/.local/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTImageProcessor, ViTModel\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "model_path = 'google/vit-base-patch16-224-in21k'\n",
    "processor = ViTImageProcessor.from_pretrained(model_path)\n",
    "#model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f67f4b39-0ef9-4e59-8b93-43b5bca1e8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTImageProcessor {\n",
       "  \"do_normalize\": true,\n",
       "  \"do_rescale\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"image_mean\": [\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5\n",
       "  ],\n",
       "  \"image_processor_type\": \"ViTImageProcessor\",\n",
       "  \"image_std\": [\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5\n",
       "  ],\n",
       "  \"resample\": 2,\n",
       "  \"rescale_factor\": 0.00392156862745098,\n",
       "  \"size\": {\n",
       "    \"height\": 224,\n",
       "    \"width\": 224\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa4efa5a-9357-4fae-93e2-c31fe8f95c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch \n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomFashionMNIST(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        \"\"\"\n",
    "        Wrap a given dataset to adjust the format of its items.\n",
    "        :param dataset: The original dataset to wrap.\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a single item from the dataset, adjusting its format.\n",
    "        \"\"\"\n",
    "        # Fetch the original item\n",
    "        item, label = self.dataset[idx]\n",
    "        \n",
    "        # Assuming 'item' is a dictionary containing 'pixel_values',\n",
    "        # adjust the format to include 'labels' in the dictionary.\n",
    "        item['labels'] = label\n",
    "\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the total number of items in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.dataset)\n",
    "\n",
    "# Apply your transforms as before\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda pil_img: pil_img.convert(\"RGB\")),\n",
    "    transforms.Lambda(lambda pil_img: processor(pil_img, return_tensors='pt'))\n",
    "])\n",
    "\n",
    "# Initialize the original datasets\n",
    "original_train_dataset = FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "original_test_dataset = FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Wrap the original datasets\n",
    "train_dataset = CustomFashionMNIST(original_train_dataset)\n",
    "test_dataset = CustomFashionMNIST(original_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2af14094-a9c9-4a37-a94f-51330dc8a84a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel_value = torch.squeeze(train_dataset[0]['pixel_values'])\n",
    "pixel_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99e7771e-ee69-4d2f-a082-6a7ed0aa6c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    pixel_values = torch.stack([torch.squeeze(x['pixel_values'], dim=0) for x in batch])\n",
    "    labels = torch.tensor([x['labels'] for x in batch])\n",
    "    \n",
    "    return {\n",
    "        'pixel_values': pixel_values,\n",
    "        'labels': labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc72371-c6c2-4ece-b601-3f8adbf0b3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kang5647/.local/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "def compute_metrics(p):\n",
    "    return metric.compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0756162-938a-4fa0-92b6-9a34d98f9ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5ff37ff0da4b3d91784b5a468d5692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f81e903a9be6404f8f841a496aedd57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTForImageClassification\n",
    "\n",
    "labels = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    model_path,\n",
    "    num_labels=len(labels),\n",
    "    id2label={str(i): c for i, c in enumerate(labels)},\n",
    "    label2id={c: str(i) for i, c in enumerate(labels)}\n",
    ")\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\"./vit-fashion-mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cf6a26c-515e-476b-ae02-c517652cbd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=\"./vit-fashion-mnist\",\n",
    "  per_device_train_batch_size=16,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=4,\n",
    "  fp16=True,\n",
    "  save_steps=100,\n",
    "  eval_steps=100,\n",
    "  logging_steps=10,\n",
    "  learning_rate=2e-4,\n",
    "  save_total_limit=2,\n",
    "  remove_unused_columns=False,\n",
    "  push_to_hub=False,\n",
    "  report_to='tensorboard',\n",
    "  load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f98173fe-f8df-457a-aa20-4a743f543f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "accelerator = Accelerator()\n",
    "\n",
    "device = accelerator.device\n",
    "model,train_dataset, test_dataset= accelerator.prepare(\n",
    "    model, train_dataset, test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98633a00-67a4-416e-987e-4b409ee89402",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/FYP/poon0064/.conda/envs/RunJupyter/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d676191-c763-41f4-86b5-a25cb285b3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13801' max='15000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13801/15000 2:07:23 < 11:04, 1.81 it/s, Epoch 3.68/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.638900</td>\n",
       "      <td>0.596072</td>\n",
       "      <td>0.817400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.445700</td>\n",
       "      <td>0.463095</td>\n",
       "      <td>0.850100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.500100</td>\n",
       "      <td>0.495619</td>\n",
       "      <td>0.831700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.322700</td>\n",
       "      <td>0.412769</td>\n",
       "      <td>0.860900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.392200</td>\n",
       "      <td>0.347485</td>\n",
       "      <td>0.880300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.336400</td>\n",
       "      <td>0.360804</td>\n",
       "      <td>0.879300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.251500</td>\n",
       "      <td>0.334698</td>\n",
       "      <td>0.887600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.453200</td>\n",
       "      <td>0.382384</td>\n",
       "      <td>0.868300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.331800</td>\n",
       "      <td>0.295076</td>\n",
       "      <td>0.898100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.411600</td>\n",
       "      <td>0.416310</td>\n",
       "      <td>0.856400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.335400</td>\n",
       "      <td>0.334209</td>\n",
       "      <td>0.889900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.325700</td>\n",
       "      <td>0.341066</td>\n",
       "      <td>0.880200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.230200</td>\n",
       "      <td>0.380746</td>\n",
       "      <td>0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.334200</td>\n",
       "      <td>0.281838</td>\n",
       "      <td>0.902000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.262400</td>\n",
       "      <td>0.379162</td>\n",
       "      <td>0.875500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.449900</td>\n",
       "      <td>0.313381</td>\n",
       "      <td>0.892600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.377800</td>\n",
       "      <td>0.288874</td>\n",
       "      <td>0.899300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.252200</td>\n",
       "      <td>0.323286</td>\n",
       "      <td>0.887800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.216600</td>\n",
       "      <td>0.295048</td>\n",
       "      <td>0.901100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.319400</td>\n",
       "      <td>0.295148</td>\n",
       "      <td>0.894400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.172500</td>\n",
       "      <td>0.271389</td>\n",
       "      <td>0.903800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.206000</td>\n",
       "      <td>0.265345</td>\n",
       "      <td>0.909400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.192700</td>\n",
       "      <td>0.266961</td>\n",
       "      <td>0.906100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.257300</td>\n",
       "      <td>0.260775</td>\n",
       "      <td>0.908400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.149200</td>\n",
       "      <td>0.276294</td>\n",
       "      <td>0.906800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.251800</td>\n",
       "      <td>0.280741</td>\n",
       "      <td>0.897100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.216200</td>\n",
       "      <td>0.257620</td>\n",
       "      <td>0.915300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.185500</td>\n",
       "      <td>0.248409</td>\n",
       "      <td>0.909600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.279900</td>\n",
       "      <td>0.271148</td>\n",
       "      <td>0.907200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.281400</td>\n",
       "      <td>0.331851</td>\n",
       "      <td>0.887900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.250100</td>\n",
       "      <td>0.245161</td>\n",
       "      <td>0.912400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.340500</td>\n",
       "      <td>0.257449</td>\n",
       "      <td>0.913000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.284000</td>\n",
       "      <td>0.240899</td>\n",
       "      <td>0.916200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.203700</td>\n",
       "      <td>0.228685</td>\n",
       "      <td>0.920500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.194800</td>\n",
       "      <td>0.229426</td>\n",
       "      <td>0.921200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.224600</td>\n",
       "      <td>0.288075</td>\n",
       "      <td>0.902000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.134600</td>\n",
       "      <td>0.243244</td>\n",
       "      <td>0.916200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.253800</td>\n",
       "      <td>0.223591</td>\n",
       "      <td>0.921100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.178900</td>\n",
       "      <td>0.248579</td>\n",
       "      <td>0.913200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.215600</td>\n",
       "      <td>0.241152</td>\n",
       "      <td>0.920600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.204100</td>\n",
       "      <td>0.244853</td>\n",
       "      <td>0.913800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.139000</td>\n",
       "      <td>0.265268</td>\n",
       "      <td>0.909200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.269800</td>\n",
       "      <td>0.222483</td>\n",
       "      <td>0.923200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.375600</td>\n",
       "      <td>0.245527</td>\n",
       "      <td>0.916500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.263980</td>\n",
       "      <td>0.906800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.224700</td>\n",
       "      <td>0.215050</td>\n",
       "      <td>0.924700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.310200</td>\n",
       "      <td>0.299071</td>\n",
       "      <td>0.898100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.158300</td>\n",
       "      <td>0.209817</td>\n",
       "      <td>0.930300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.197800</td>\n",
       "      <td>0.230897</td>\n",
       "      <td>0.915200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.213900</td>\n",
       "      <td>0.220789</td>\n",
       "      <td>0.925300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>0.210784</td>\n",
       "      <td>0.927400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.241700</td>\n",
       "      <td>0.227701</td>\n",
       "      <td>0.920300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.162700</td>\n",
       "      <td>0.207419</td>\n",
       "      <td>0.929000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.242500</td>\n",
       "      <td>0.214587</td>\n",
       "      <td>0.926000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>0.198462</td>\n",
       "      <td>0.932600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.193900</td>\n",
       "      <td>0.218773</td>\n",
       "      <td>0.923800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.157100</td>\n",
       "      <td>0.185383</td>\n",
       "      <td>0.935800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.186800</td>\n",
       "      <td>0.216219</td>\n",
       "      <td>0.926300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.216100</td>\n",
       "      <td>0.200548</td>\n",
       "      <td>0.928600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.148000</td>\n",
       "      <td>0.221869</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.064400</td>\n",
       "      <td>0.251030</td>\n",
       "      <td>0.919300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.204500</td>\n",
       "      <td>0.224031</td>\n",
       "      <td>0.922500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.232900</td>\n",
       "      <td>0.212698</td>\n",
       "      <td>0.926200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>0.215412</td>\n",
       "      <td>0.926900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.257900</td>\n",
       "      <td>0.174761</td>\n",
       "      <td>0.938600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.136100</td>\n",
       "      <td>0.218015</td>\n",
       "      <td>0.925400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.199700</td>\n",
       "      <td>0.204053</td>\n",
       "      <td>0.931000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.135200</td>\n",
       "      <td>0.237284</td>\n",
       "      <td>0.920200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.210290</td>\n",
       "      <td>0.927700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.164400</td>\n",
       "      <td>0.195927</td>\n",
       "      <td>0.933800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>0.185900</td>\n",
       "      <td>0.205400</td>\n",
       "      <td>0.931200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.154800</td>\n",
       "      <td>0.247780</td>\n",
       "      <td>0.916400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>0.164100</td>\n",
       "      <td>0.186916</td>\n",
       "      <td>0.937000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>0.144200</td>\n",
       "      <td>0.259066</td>\n",
       "      <td>0.917500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.096800</td>\n",
       "      <td>0.187597</td>\n",
       "      <td>0.934800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.132700</td>\n",
       "      <td>0.187206</td>\n",
       "      <td>0.936200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>0.163100</td>\n",
       "      <td>0.194134</td>\n",
       "      <td>0.937800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>0.071200</td>\n",
       "      <td>0.193311</td>\n",
       "      <td>0.936100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>0.146400</td>\n",
       "      <td>0.200400</td>\n",
       "      <td>0.936500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.263600</td>\n",
       "      <td>0.206414</td>\n",
       "      <td>0.932600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>0.133100</td>\n",
       "      <td>0.188545</td>\n",
       "      <td>0.939500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>0.063900</td>\n",
       "      <td>0.204564</td>\n",
       "      <td>0.937300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>0.089300</td>\n",
       "      <td>0.192935</td>\n",
       "      <td>0.936900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>0.139000</td>\n",
       "      <td>0.198306</td>\n",
       "      <td>0.936700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.137000</td>\n",
       "      <td>0.183536</td>\n",
       "      <td>0.936800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>0.161800</td>\n",
       "      <td>0.179777</td>\n",
       "      <td>0.941400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>0.095900</td>\n",
       "      <td>0.214103</td>\n",
       "      <td>0.931000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>0.149800</td>\n",
       "      <td>0.186961</td>\n",
       "      <td>0.938500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.175962</td>\n",
       "      <td>0.942300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.222200</td>\n",
       "      <td>0.198196</td>\n",
       "      <td>0.933200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>0.135800</td>\n",
       "      <td>0.201321</td>\n",
       "      <td>0.936400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>0.176700</td>\n",
       "      <td>0.196441</td>\n",
       "      <td>0.935300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>0.116500</td>\n",
       "      <td>0.193854</td>\n",
       "      <td>0.936000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>0.191260</td>\n",
       "      <td>0.939800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.106700</td>\n",
       "      <td>0.205515</td>\n",
       "      <td>0.936400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>0.180300</td>\n",
       "      <td>0.175778</td>\n",
       "      <td>0.942400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9700</td>\n",
       "      <td>0.113600</td>\n",
       "      <td>0.196174</td>\n",
       "      <td>0.934700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>0.120700</td>\n",
       "      <td>0.181893</td>\n",
       "      <td>0.942000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9900</td>\n",
       "      <td>0.123900</td>\n",
       "      <td>0.175747</td>\n",
       "      <td>0.943400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.097800</td>\n",
       "      <td>0.181966</td>\n",
       "      <td>0.939600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10100</td>\n",
       "      <td>0.096500</td>\n",
       "      <td>0.193820</td>\n",
       "      <td>0.938800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>0.145100</td>\n",
       "      <td>0.185259</td>\n",
       "      <td>0.938100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10300</td>\n",
       "      <td>0.163000</td>\n",
       "      <td>0.184926</td>\n",
       "      <td>0.941200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>0.107200</td>\n",
       "      <td>0.178774</td>\n",
       "      <td>0.939700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.129200</td>\n",
       "      <td>0.177060</td>\n",
       "      <td>0.939500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>0.178600</td>\n",
       "      <td>0.188378</td>\n",
       "      <td>0.938300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10700</td>\n",
       "      <td>0.131100</td>\n",
       "      <td>0.172140</td>\n",
       "      <td>0.942600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>0.083200</td>\n",
       "      <td>0.175870</td>\n",
       "      <td>0.941100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10900</td>\n",
       "      <td>0.128600</td>\n",
       "      <td>0.174526</td>\n",
       "      <td>0.942700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.083400</td>\n",
       "      <td>0.167011</td>\n",
       "      <td>0.943500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11100</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>0.170296</td>\n",
       "      <td>0.945000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>0.056900</td>\n",
       "      <td>0.170320</td>\n",
       "      <td>0.945200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11300</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>0.163273</td>\n",
       "      <td>0.946200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11400</td>\n",
       "      <td>0.108500</td>\n",
       "      <td>0.166016</td>\n",
       "      <td>0.947500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.067600</td>\n",
       "      <td>0.175612</td>\n",
       "      <td>0.947100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11600</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>0.182857</td>\n",
       "      <td>0.945900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11700</td>\n",
       "      <td>0.058100</td>\n",
       "      <td>0.183875</td>\n",
       "      <td>0.947500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11800</td>\n",
       "      <td>0.119400</td>\n",
       "      <td>0.189256</td>\n",
       "      <td>0.945200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11900</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>0.187220</td>\n",
       "      <td>0.946000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.130600</td>\n",
       "      <td>0.188968</td>\n",
       "      <td>0.946500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12100</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.186097</td>\n",
       "      <td>0.943400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12200</td>\n",
       "      <td>0.045700</td>\n",
       "      <td>0.192680</td>\n",
       "      <td>0.946200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12300</td>\n",
       "      <td>0.016300</td>\n",
       "      <td>0.196641</td>\n",
       "      <td>0.946500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12400</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>0.187118</td>\n",
       "      <td>0.948000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>0.187984</td>\n",
       "      <td>0.947600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12600</td>\n",
       "      <td>0.080700</td>\n",
       "      <td>0.190524</td>\n",
       "      <td>0.947800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12700</td>\n",
       "      <td>0.097500</td>\n",
       "      <td>0.188746</td>\n",
       "      <td>0.947000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12800</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>0.193254</td>\n",
       "      <td>0.944500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12900</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>0.179410</td>\n",
       "      <td>0.948500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.044200</td>\n",
       "      <td>0.187068</td>\n",
       "      <td>0.946700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13100</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.194625</td>\n",
       "      <td>0.947300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13200</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.194166</td>\n",
       "      <td>0.950400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13300</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.198950</td>\n",
       "      <td>0.946900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13400</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>0.191810</td>\n",
       "      <td>0.948500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.070500</td>\n",
       "      <td>0.189121</td>\n",
       "      <td>0.948100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13600</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.188027</td>\n",
       "      <td>0.949100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13700</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>0.185860</td>\n",
       "      <td>0.949500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 570/1250 00:16 < 00:20, 33.89 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_results = trainer.train()\n",
    "trainer.save_model()\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcadb5c-f4d2-421e-aef3-83697f2d8e2c",
   "metadata": {},
   "source": [
    "## Resume from training error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cfba60c-bde4-4f14-9096-65b1ce7d82b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the best model at ./vit-fashion-mnist/checkpoint-11300/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15000' max='15000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15000/15000 : < :, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =           4.0\n",
      "  total_flos               = 17322051354GF\n",
      "  train_loss               =           0.0\n",
      "  train_runtime            =    0:00:00.05\n",
      "  train_samples_per_second =    4647793.04\n",
      "  train_steps_per_second   =    290487.065\n"
     ]
    }
   ],
   "source": [
    "train_results = trainer.train(resume_from_checkpoint = True)\n",
    "trainer.save_model()\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edd16db-e21d-4e5f-9c0c-0e491c8bfecd",
   "metadata": {},
   "source": [
    "## Predict samples of test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "785fdcf0-65eb-42db-80c8-340224308981",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate(test_dataset)\n\u001b[1;32m      2\u001b[0m trainer\u001b[38;5;241m.\u001b[39mlog_metrics(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics)\n\u001b[1;32m      3\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_metrics(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate(test_dataset)\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "920c81be-477f-44b7-bda9-41c5675576fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pixel_values': tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       " \n",
       "          [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       " \n",
       "          [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]]]]), 'labels': 5},\n",
       " {'pixel_values': tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       " \n",
       "          [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       " \n",
       "          [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]]]]), 'labels': 1},\n",
       " {'pixel_values': tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       " \n",
       "          [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       " \n",
       "          [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]]]]), 'labels': 7},\n",
       " {'pixel_values': tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       " \n",
       "          [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       " \n",
       "          [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]]]]), 'labels': 4},\n",
       " {'pixel_values': tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       " \n",
       "          [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       " \n",
       "          [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]]]]), 'labels': 3},\n",
       " {'pixel_values': tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       " \n",
       "          [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       " \n",
       "          [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]]]]), 'labels': 0},\n",
       " {'pixel_values': tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       " \n",
       "          [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       " \n",
       "          [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]]]]), 'labels': 4},\n",
       " {'pixel_values': tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       " \n",
       "          [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       " \n",
       "          [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]]]]), 'labels': 7},\n",
       " {'pixel_values': tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       " \n",
       "          [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       " \n",
       "          [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]]]]), 'labels': 1}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "test_samples = []\n",
    "for sample in random.sample(list(test_dataset), k=9):\n",
    "    test_samples.append(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3761178-d576-4767-a748-3d86fbe74687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** predict metrics *****\n",
      "  predict_accuracy           =        1.0\n",
      "  predict_loss               =     0.0112\n",
      "  predict_runtime            = 0:00:00.04\n",
      "  predict_samples_per_second =    184.041\n",
      "  predict_steps_per_second   =     40.898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([5, 1, 7, 4, 3, 0, 4, 7, 1]), array([5, 1, 7, 4, 3, 0, 4, 7, 1]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds, labels, metrics = trainer.predict(test_samples, metric_key_prefix=\"predict\")\n",
    "trainer.log_metrics(\"predict\", metrics)\n",
    "trainer.save_metrics(\"predict\", metrics)\n",
    "\n",
    "pred_classes = predictions = np.argmax(preds, axis=1)\n",
    "\n",
    "pred_classes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52723b6-aaa6-44f5-92eb-b6ce6a19bb51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
